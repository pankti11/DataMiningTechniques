{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys\n",
    "import os\n",
    "stopwords = feature_extraction.text.ENGLISH_STOP_WORDS\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "import operator\n",
    "import math\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n",
    "import random\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from soft_clustering_measure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"/Users/panktibhalani/Downloads/whole_dataset.txt\", \"r\");\n",
    "lines = text_file.readlines();\n",
    "labels = []\n",
    "doctext = []\n",
    "for line in lines:\n",
    "    line = line[1:-1]\n",
    "    listoflines = line.split(',', 2)\n",
    "    doctext.append(listoflines[2].strip())\n",
    "    labels.append(listoflines[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(wordlist):\n",
    "    return [w for w in wordlist if w not in stopwords]\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(sentence):\n",
    "    sentence = strip_punctuation(sentence.lower())\n",
    "    list_of_words = sentence.split();\n",
    "    list_of_words = removeStopwords(list_of_words);\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematized_word(postaged,word):\n",
    "    try:\n",
    "        postager = get_wordnet_pos(postaged[word])\n",
    "        if(postager == ''):\n",
    "            lmzword = lemmatiser.lemmatize(word)\n",
    "        else:\n",
    "            lmzword = lemmatiser.lemmatize(word,pos=postager)\n",
    "    except:\n",
    "        lmzword = lemmatiser.lemmatize(word)\n",
    "    return lmzword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for doc in doctext:\n",
    "    doc = doc.strip()\n",
    "    doc.replace(\"\\n\",\" \")\n",
    "    sentences = re.split(\"[!.]\",doc)\n",
    "    wordlist = []\n",
    "    for sentence in sentences:\n",
    "        postaged = dict(pos_tag(word_tokenize(sentence)))\n",
    "        list_of_words = getwords(sentence)\n",
    "        for word in list_of_words:\n",
    "            lmzword = lematized_word(postaged,word)\n",
    "            wordlist.append(lmzword)\n",
    "    document.append(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDoc = []\n",
    "for doc in document:\n",
    "    cleanedDoc.append(\" \".join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TopDocs(model, feature_names, no_top_words):\n",
    "    Topics=[]\n",
    "    for topicid, topic in enumerate(model.components_):\n",
    "        topic_norm=np.linalg.norm(topic)\n",
    "        if topic_norm != 0:\n",
    "            topic=topic/topic_norm\n",
    "        Topics.append(topic)\n",
    "    return np.array(Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english')\n",
    "termfq = count_vectorizer.fit_transform(cleanedDoc)\n",
    "count_feature_names = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 50\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(termfq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lda.transform(termfq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846, 50)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "setoflabels = set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setoflabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictla = {}\n",
    "ind = 0\n",
    "for l in setoflabels:\n",
    "    dictla[l] = ind\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'alt.atheism'\": 8,\n",
       " \"'comp.graphics'\": 2,\n",
       " \"'comp.os.ms-windows.misc'\": 6,\n",
       " \"'comp.sys.ibm.pc.hardware'\": 9,\n",
       " \"'comp.sys.mac.hardware'\": 17,\n",
       " \"'comp.windows.x'\": 14,\n",
       " \"'misc.forsale'\": 18,\n",
       " \"'rec.autos'\": 16,\n",
       " \"'rec.motorcycles'\": 15,\n",
       " \"'rec.sport.baseball'\": 3,\n",
       " \"'rec.sport.hockey'\": 0,\n",
       " \"'sci.crypt'\": 13,\n",
       " \"'sci.electronics'\": 4,\n",
       " \"'sci.med'\": 5,\n",
       " \"'sci.space'\": 11,\n",
       " \"'soc.religion.christian'\": 19,\n",
       " \"'talk.politics.guns'\": 7,\n",
       " \"'talk.politics.mideast'\": 12,\n",
       " \"'talk.politics.misc'\": 1,\n",
       " \"'talk.religion.misc'\": 10}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"/Users/panktibhalani/Downloads/sample_dataset.txt\", \"r\");\n",
    "lines = text_file.readlines();\n",
    "indexestemp = []\n",
    "for line in lines:\n",
    "    lines= line.split(\",\")\n",
    "    indexestemp.append(int(lines[0][1:]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtereddata = result[indexestemp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4491"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtereddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(20, 50)\n",
      "(20, 50)\n",
      "[0.0747084  0.02841395 0.03520461 0.05381435 0.06264997 0.03246752\n",
      " 0.05069387 0.02568824 0.05158759 0.05101883 0.03384547 0.03296543\n",
      " 0.03958851 0.0677129  0.04548254 0.04864706 0.04599019 0.08457217\n",
      " 0.05898456 0.07596384]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmmresultfsh = GaussianMixture(n_components=20, covariance_type='diag').fit(filtereddata)\n",
    "print(gmmresultfsh.converged_)\n",
    "print(gmmresultfsh.covariances_.shape)\n",
    "print(gmmresultfsh.means_.shape)\n",
    "print(gmmresultfsh.weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gmmresultfsh.predict_proba(filtereddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredlabels = labels[indexestemp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstobesent = []\n",
    "\n",
    "for eacl in filteredlabels:\n",
    "    labelstobesent.append(dictla[eacl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'alt.atheism'\": 8,\n",
       " \"'comp.graphics'\": 2,\n",
       " \"'comp.os.ms-windows.misc'\": 6,\n",
       " \"'comp.sys.ibm.pc.hardware'\": 9,\n",
       " \"'comp.sys.mac.hardware'\": 17,\n",
       " \"'comp.windows.x'\": 14,\n",
       " \"'misc.forsale'\": 18,\n",
       " \"'rec.autos'\": 16,\n",
       " \"'rec.motorcycles'\": 15,\n",
       " \"'rec.sport.baseball'\": 3,\n",
       " \"'rec.sport.hockey'\": 0,\n",
       " \"'sci.crypt'\": 13,\n",
       " \"'sci.electronics'\": 4,\n",
       " \"'sci.med'\": 5,\n",
       " \"'sci.space'\": 11,\n",
       " \"'soc.religion.christian'\": 19,\n",
       " \"'talk.politics.guns'\": 7,\n",
       " \"'talk.politics.mideast'\": 12,\n",
       " \"'talk.politics.misc'\": 1,\n",
       " \"'talk.religion.misc'\": 10}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.555765189164771"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_homogeneity(predictions,labelstobesent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5300046270821026"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_completeness(predictions,labelstobesent,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 20\n",
    "lda20 = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(termfq)\n",
    "result20 = lda20.transform(termfq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtereddata20 = result20[indexestemp]\n",
    "gmmresultfsh20 = GaussianMixture(n_components=20, covariance_type='diag').fit(filtereddata20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions20 = gmmresultfsh20.predict_proba(filtereddata20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5386416409682417"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_homogeneity(predictions20,labelstobesent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.498867324812917"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_completeness(predictions20,labelstobesent,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtereddata20 = result20[indexestemp]\n",
    "gmmresultfsh10 = GaussianMixture(n_components=10, covariance_type='diag').fit(filtereddata20)\n",
    "predictions10 = gmmresultfsh10.predict_proba(filtereddata20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6088813614416884"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_homogeneity(predictions10,labelstobesent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9151530010559497"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_completeness(predictions10,labelstobesent,10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 10\n",
    "lda10 = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(termfq)\n",
    "result10 = lda10.transform(termfq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtereddata10 = result10[indexestemp]\n",
    "gmmresultfsh1020 = GaussianMixture(n_components=10, covariance_type='diag').fit(filtereddata10)\n",
    "predictions1020 = gmmresultfsh1020.predict_proba(filtereddata10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5627124977540694"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_homogeneity(predictions1020,labelstobesent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.912888232611154"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_completeness(predictions1020,labelstobesent,10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4491, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions10.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(10,np.float32)\n",
    "\n",
    "for eachdoc in predictions10:\n",
    "    a = np.add(a,eachdoc) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "max1 = np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "index = 0\n",
    "for b in gmmresultfsh10.predict(filtereddata20):\n",
    "    if(b == 4):\n",
    "        points.append(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for eachtop in points:\n",
    "    label = labelstobesent[eachtop]\n",
    "    \n",
    "    if label in temp:\n",
    "        temp[label] += 1\n",
    "    else:\n",
    "        temp[label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 2: 101,\n",
       " 3: 1,\n",
       " 4: 20,\n",
       " 5: 4,\n",
       " 6: 103,\n",
       " 7: 1,\n",
       " 8: 1,\n",
       " 9: 107,\n",
       " 10: 1,\n",
       " 11: 9,\n",
       " 13: 13,\n",
       " 14: 140,\n",
       " 15: 14,\n",
       " 16: 8,\n",
       " 17: 86,\n",
       " 18: 43,\n",
       " 19: 2}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [14,6,9,17,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'comp.graphics'\n",
      "'comp.os.ms-windows.misc'\n",
      "'comp.sys.ibm.pc.hardware'\n",
      "'comp.windows.x'\n",
      "'comp.sys.mac.hardware'\n"
     ]
    }
   ],
   "source": [
    "for key in dictla:\n",
    "    if dictla[key] in list1:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "es = elasticsearch.Elasticsearch()\n",
    "def show_top20(classifier, vectorizer,no_top_words,type1,data):\n",
    "    \n",
    "    index_no = type1 + data\n",
    "    doc20Ngtype = type1 + data + \"type\"\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(classifier.components_):\n",
    "        print(i)\n",
    "        \n",
    "        top_words=category.argsort()[:-no_top_words - 1:-1]\n",
    "        words = []\n",
    "        for j in top_words:\n",
    "            print(feature_names[j],category[j])\n",
    "            words.append(feature_names[j])\n",
    "        \n",
    "        print(\"**************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "armenian 2555.9249539253483\n",
      "say 1844.6438811953346\n",
      "come 1227.650433432521\n",
      "israel 1181.7965708235108\n",
      "win 894.9647925872529\n",
      "**************************************************************************\n",
      "1\n",
      "child 1619.5280723395213\n",
      "car 1326.641322977526\n",
      "woman 1127.4291285793213\n",
      "turkish 978.4817844771253\n",
      "father 736.3595082790227\n",
      "**************************************************************************\n",
      "2\n",
      "sell 953.1153968539671\n",
      "price 880.8250733327653\n",
      "arm 785.1483685842175\n",
      "weapon 782.3359225166859\n",
      "phone 768.1796294901937\n",
      "**************************************************************************\n",
      "3\n",
      "edu 2068.5612735605805\n",
      "file 2035.6539574608648\n",
      "com 1191.143139689959\n",
      "list 1036.0695463983207\n",
      "send 1030.0753496649536\n",
      "**************************************************************************\n",
      "4\n",
      "god 4171.172771340497\n",
      "christian 1819.110738842286\n",
      "believe 1614.9369557457267\n",
      "jesus 1531.8484316062286\n",
      "say 1504.7286288908435\n",
      "**************************************************************************\n",
      "5\n",
      "use 1370.0377346552732\n",
      "image 1167.1528266542166\n",
      "program 1058.7639695304742\n",
      "sin 853.4483259624969\n",
      "greek 664.3542856665366\n",
      "**************************************************************************\n",
      "6\n",
      "power 1250.0827989713575\n",
      "time 1226.7202711834293\n",
      "line 597.7656758798039\n",
      "water 569.3795998822569\n",
      "hit 569.2967745658672\n",
      "**************************************************************************\n",
      "7\n",
      "like 3313.2625886610463\n",
      "just 3247.8140794612827\n",
      "dont 2711.8368981161693\n",
      "im 2650.101303222185\n",
      "think 2474.417568683741\n",
      "**************************************************************************\n",
      "8\n",
      "year 1078.235166374425\n",
      "new 845.4588224816488\n",
      "pay 608.1851977169475\n",
      "tax 597.4591370977405\n",
      "money 587.228153228068\n",
      "**************************************************************************\n",
      "9\n",
      "drive 1724.8565210526415\n",
      "disk 717.2595144579379\n",
      "hard 527.456556582295\n",
      "scsi 350.27208076167676\n",
      "engine 325.7767947196395\n",
      "**************************************************************************\n",
      "10\n",
      "case 1043.9626212591922\n",
      "claim 1029.9159469970634\n",
      "evidence 1017.9782166910493\n",
      "point 897.9702009883908\n",
      "use 886.4827798519515\n",
      "**************************************************************************\n",
      "11\n",
      "people 2460.1804688866837\n",
      "government 2395.733501615218\n",
      "law 2152.7584783117895\n",
      "right 1977.513148628719\n",
      "gun 1719.6040609085073\n",
      "**************************************************************************\n",
      "12\n",
      "qt 1589.4005616723607\n",
      "space 1309.1294490845867\n",
      "software 781.9510884444295\n",
      "package 695.1215383975439\n",
      "available 670.8122392108487\n",
      "**************************************************************************\n",
      "13\n",
      "president 1518.0825287186733\n",
      "report 1188.7937426420383\n",
      "university 1113.6793645546422\n",
      "national 959.5132350120743\n",
      "state 866.4393082572941\n",
      "**************************************************************************\n",
      "14\n",
      "10 1457.015166173078\n",
      "12 951.3826221686778\n",
      "20 785.9331926924375\n",
      "israeli 781.4523346931103\n",
      "11 742.5048671639609\n",
      "**************************************************************************\n",
      "15\n",
      "window 1457.6189399052516\n",
      "use 1137.660659598704\n",
      "card 945.8988527489882\n",
      "run 924.4098743324998\n",
      "driver 705.7593679568465\n",
      "**************************************************************************\n",
      "16\n",
      "game 1844.6516395140034\n",
      "play 1232.7505765398382\n",
      "book 772.1714730418837\n",
      "arab 750.0789367056435\n",
      "period 607.7156076526227\n",
      "**************************************************************************\n",
      "17\n",
      "dont 2901.90427136749\n",
      "think 2838.781616227009\n",
      "say 2764.0751298251366\n",
      "people 2435.5015361883534\n",
      "know 2413.6265887596624\n",
      "**************************************************************************\n",
      "18\n",
      "use 2773.665816169556\n",
      "key 1729.8841636643458\n",
      "data 1025.6971185740265\n",
      "chip 748.9195101792616\n",
      "encryption 594.4457605788473\n",
      "**************************************************************************\n",
      "19\n",
      "year 1925.50881534371\n",
      "team 1288.308892093857\n",
      "player 780.7844349658394\n",
      "launch 690.1065459188071\n",
      "turkey 607.650989516123\n",
      "**************************************************************************\n"
     ]
    }
   ],
   "source": [
    "show_top20(lda20, count_vectorizer, 5,\"nmf\",\"20ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
