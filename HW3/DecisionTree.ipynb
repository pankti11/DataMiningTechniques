{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import operator\n",
    "import numpy as np\n",
    "from custom import calculateEvaluationmatrixnew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import text \n",
    "stop_wordstemp = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 129796)\n",
      "(7532, 129796)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "\n",
    "newsgroups_trainlabel = newsgroups_train.target\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_wordstemp)\n",
    "vectorstrain = vectorizer.fit_transform(newsgroups_train.data)\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "vocab = vectorizer.vocabulary_\n",
    "newvectorizer = TfidfVectorizer(vocabulary=vocab,stop_words=stop_wordstemp)\n",
    "vectorstest = newvectorizer.fit_transform(newsgroups_test.data)\n",
    "newsgroups_testlabel = newsgroups_test.target\n",
    "print(vectorstrain.shape)\n",
    "print(vectorstest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5434700727603616"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = Lasso(alpha=0.001)\n",
    "LResult = LR.fit(vectorstrain,newsgroups_trainlabel)\n",
    "LResult.score(vectorstest,newsgroups_testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108704  58381  39305 103385  92475  87959 116445  29409 102510 110128\n",
      "  45320 104475  47086  90133  55451  94587 109079  89911  76750  41033\n",
      "  75246  79646 113973 129116 102519  45177  45431  40635  89502  65318\n",
      "  39543  80203 106945  62004 108978  29250  28122  29968  98155 116821\n",
      " 113905  92015 110738  54411  29080  49128  75684 110137  92578  29214\n",
      " 114322  37961  46530  84304  76629  86747 104158  32607  70462  98815\n",
      "  30462 116751  74663  29372  69309  26872 105048  96099  42873  96146\n",
      "  34131  72569 105732  81949  69796  32338  60806  95559  90177  58076\n",
      " 110962 127721  56142  70908  27812 113353  72066  41046  64032  58098\n",
      "  34174  60783  45466 119609  54502  69768  49053 114728  81057  42757\n",
      "  88154  93838  74476  39545  54666  68557  92726  93042  68556 105975\n",
      "  62547 114894  56817  39538  38095 121369  84083  47180 102784  60165\n",
      " 105041  56724  39866 115249  70569  64445  92220  73820 106162  56451\n",
      "  56715  89982  62352  68251   6475  59517  63039  39525  94797 101806\n",
      " 104372 117790 123326 107314 113088  30111  91515 122722  38828 123454\n",
      "  68387 116756  72512  40364 108840  51607  55395  63656  34674 121783\n",
      "  96658  30096  70300 116184  33841  39647  26155 108834  43168  94616\n",
      "  27230  83485  90091  25389 116118  35139  48328  79038  41879  71539\n",
      "  62669 107700 124966  58200  33154  50461  50976  56630  61581  29374\n",
      "  40314  39957  68158  29371  59801  39315  41229  30058  26889  74611]\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "coefs=LResult.coef_\n",
    "top_200 = np.argpartition(coefs, -200)[-200:]\n",
    "print(top_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999203398831652"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_2 = DecisionTreeClassifier(max_depth=10)\n",
    "regr_20NG = regr_2.fit(vectorstrain,newsgroups_trainlabel)\n",
    "regr_20NG.score(vectorstest,newsgroups_testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizertemp = TfidfVectorizer(vocabulary=feature_names[top_200])\n",
    "vectorstraintop200 = vectorizertemp.fit_transform(newsgroups_train.data)\n",
    "newvectorizertemp = TfidfVectorizer(vocabulary=feature_names[top_200])\n",
    "vectorstesttop200 = newvectorizertemp.fit_transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18268720127456187"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_20NG = regr_2.fit(vectorstraintop200,newsgroups_trainlabel)\n",
    "regr_20NG.score(vectorstesttop200,newsgroups_testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25332 20624 18081 17100  2173  5964 16508 11107 14286  3878  4985 10788\n",
      "   598 15264 25132 20762 14496  9535  5727 14135 20000 28888 16048 27706\n",
      " 20130 19338 10684  4912  5212 26281 20378  1993 20674   269  9276 10195\n",
      " 16264 10810 12691 20590  7886   270 13240  7293  7666  3060 15876 19080\n",
      " 26713 20825 28526  9381 14904 28264 18385 11360  5336 14796 12554 12478\n",
      " 10738 16851  5230  7530 12561  5360 24124 16722  7704 12644 24164 19747\n",
      " 12701 12731 11197 20111 12249 24284 12785 11083 24315 16498 17108 12811\n",
      " 26852 12824   114 16462 20272 16361  9767 17192 23587 27671  1566 11223\n",
      " 24472 23440 19450  5885 10805  9910 13198 27879 27906  4058 26623 16072\n",
      " 26621 20605   229 13359 17424 15931 23187 24712 17510  8594 13410 23042\n",
      "  6284 24788 28219 17588 20914 11010  6430 25993 24836  8285  6520 19088\n",
      " 21682 13829 21174 15442 19073 11644 13924 11625 18429 13997 13998  4370\n",
      "  4348 10887  4322 10364 26145 26128 10403  7938  6871 25075 26084 21461\n",
      " 25092 10462 18801  6909 14193 10475 28969  7044  4180 16546  9335 11406\n",
      " 19078 10519 24832  4495 17591  9937 12004 24496  9844 12271  9627 19775\n",
      " 10700 19863 27265 23736 23699 25717 23416 27847 23194  3865 20831 29104\n",
      "  6283 28357 28428  8067 18428 21361 28983 21634]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6134301270417423"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = ['alt.atheism','comp.graphics','sci.space']\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\",categories=cat)\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\",categories=cat)\n",
    "\n",
    "newsgroups_trainlabel = newsgroups_train.target\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_wordstemp)\n",
    "vectorstrain = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vocab = vectorizer.vocabulary_\n",
    "newvectorizer = TfidfVectorizer(vocabulary=vocab,stop_words=stop_wordstemp)\n",
    "vectorstest = newvectorizer.fit_transform(newsgroups_test.data)\n",
    "newsgroups_testlabel = newsgroups_test.target\n",
    "\n",
    "LR = Lasso(alpha=0.0001)\n",
    "LResult = LR.fit(vectorstrain,newsgroups_trainlabel)\n",
    "LResult.score(vectorstest,newsgroups_testlabel)\n",
    "\n",
    "feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "coefs=LResult.coef_\n",
    "top_200 = np.argpartition(coefs, -200)[-200:]\n",
    "print(top_200)\n",
    "\n",
    "vectorizertemp = TfidfVectorizer(vocabulary=feature_names[top_200])\n",
    "vectorstraintop200 = vectorizertemp.fit_transform(newsgroups_train.data)\n",
    "newvectorizertemp = TfidfVectorizer(vocabulary=feature_names[top_200])\n",
    "vectorstesttop200 = newvectorizertemp.fit_transform(newsgroups_test.data)\n",
    "\n",
    "regr_20NG = regr_2.fit(vectorstraintop200,newsgroups_trainlabel)\n",
    "regr_20NG.score(vectorstesttop200,newsgroups_testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
